<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Large Data Sets in Python: Pandas And The Alternatives &mdash; CodeSolid.com 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=19645805"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="How to Use the Pandas Groupby Method?" href="../pandas-groupby/" />
    <link rel="prev" title="Data cleaning in Pandas" href="../data-cleaning-in-pandas/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../" class="icon icon-home">
            CodeSolid.com
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Featured Articles:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../using-latex-in-python/">Using LaTeX In Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing-pyenv-on-a-mac/">Installing Pyenv on a Mac (A Setup Guide With Usage Tips)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../conda-vs-pip/">Conda vs. Pip, Venv, and Pyenv – Simplicity Wins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jupyter-password/">Jupyter Password: Easy Notebook and Lab Configuration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Added Recently:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../math/taking-calculus-in-your-sixties/">Can You Take Calculus In Your Sixties?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/exploring_basic_number_theory_in_python/">Exploring Basic Number Theory in Python</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Categories</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../category-math-and-math-software/">Math and Math Software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-python/">Python (General)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-python-for-beginners-posts/">Python for Beginners</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-python-functions/">Python Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-python-math-and-science/">Python Math and Science</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-python-practice/">Python Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-python-tools/">Python Tools</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../category-pandas/">Pandas</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../selecting-data-in-pandas/">Selecting Data in Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-pyarrow-and-parquet/">Python Parquet and Arrow:  Using PyArrow with Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-pyarrow-and-parquet/#python-parquet-and-arrow-using-pyarrow-with-pandaspickup-2019-03-23-20-21-09-000000000-2019-03-04-16-11-55-000000000-2019-03-27-17-53-01-000000000-2019-03-10-01-23-59-000000000-2019-03-30-13-27-42-000000000">Python Parquet and Arrow:  Using PyArrow with Pandaspickup: [[2019-03-23 20:21:09.000000000,2019-03-04 16:11:55.000000000,2019-03-27 17:53:01.000000000,2019-03-10 01:23:59.000000000,2019-03-30 13:27:42.000000000]]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kaggle-datasets/">Using the Kaggle Datasets API in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sql-with-pandas/">Using SQL With Pandas:  PandasSQL and IPython-SQL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-data-analysis-starter-project/">Python Data Analysis Starter Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../alternatives-to-pandas-python-polars/">Alternatives to Pandas:  Python Polars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pandas-practice-examples/">Pandas Examples and Review Questions to Make You an Expert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../google-sheets-in-python-and-pandas/">How to Work With Google Sheets In Python and Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data-cleaning-in-pandas/">Data cleaning in Pandas</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Large Data Sets in Python:  Pandas And The Alternatives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#approaches-to-optimizing-dataframe-load-times">Approaches to Optimizing DataFrame Load Times</a></li>
<li class="toctree-l3"><a class="reference internal" href="#setting-up-our-environment">Setting Up Our Environment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#polars-a-fast-dataframe-implementation-with-a-slick-api">Polars: A Fast DataFrame implementation with a Slick API</a></li>
<li class="toctree-l3"><a class="reference internal" href="#large-data-sets-with-alternate-file-types">Large Data Sets With Alternate File Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="#speeding-things-up-with-lazy-mode">Speeding Things Up With Lazy Mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dask-vs-polars-lazy-mode-showdown">Dask vs. Polars: Lazy Mode Showdown</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#lazy-loading-of-rows-in-dask">Lazy Loading of Rows in Dask</a></li>
<li class="toctree-l4"><a class="reference internal" href="#lazy-mode-in-polars">Lazy Mode in Polars</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#closing-thoughts">Closing Thoughts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#you-may-also-like">You May Also Like</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../pandas-groupby/">How to Use the Pandas Groupby Method?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to-visualize-data-using-pandas/">How to Visualize Data Using Pandas</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../category-newsletter/">Newsletter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-miscellaneous/">Other</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-c-and-cplusplus/">C and C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-docker/">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-jupyter/">Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../category-learn-to-code/">Learn to Code</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../">CodeSolid.com</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../category-pandas/">Pandas</a></li>
      <li class="breadcrumb-item active">Large Data Sets in Python:  Pandas And The Alternatives</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/large-data-sets-in-python-pandas-and-the-alternatives.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="large-data-sets-in-python-pandas-and-the-alternatives">
<h1>Large Data Sets in Python:  Pandas And The Alternatives<a class="headerlink" href="#large-data-sets-in-python-pandas-and-the-alternatives" title="Link to this heading"></a></h1>
<p>Pandas is an excellent tool for representing in-memory DataFrames. Still, it is limited by system memory and is not always the most efficient tool for dealing with large data sets. Beyond a certain point, we even have to set aside Pandas and consider “big-data” tools such as Hadoop and Spark.</p>
<p>Even before that point, we may find we want to optimize performance, especially during data load. We may think nothing of loading a gigabyte dataset or more into memory on a modern machine, but the performance might not be ideal.</p>
<p>In this article, we’ll discuss and explore several approaches to this problem. A Jupyter Notebook with the source on which the article was based can be found in this <a class="reference external" href="https://github.com/CodeSolid/large-datasets">GitHub repository</a>.</p>
<section id="approaches-to-optimizing-dataframe-load-times">
<h2>Approaches to Optimizing DataFrame Load Times<a class="headerlink" href="#approaches-to-optimizing-dataframe-load-times" title="Link to this heading"></a></h2>
<p>There are several ways to approach this problem.</p>
<p>First, we might try giving Pandas more information, such as pre-loading the column types when loading CSV, so Pandas doesn’t have to add “figuring out the schema” to the other things it has to do during load. Though this works well and saves time, the savings are not substantial, as we’ll see below.</p>
<p>Another approach is to save the DataFrame to another file type where the load time can be reduced. Of course, this does beg the question of poor performance on the first load, but it can make subsequent analyses less painful.</p>
<p>Finally, some alternatives to Pandas have appeared that can either load the complete data set faster than Pandas can or that work in a “lazy” fashion, which may only load portions of the data as needed to fulfill a request.</p>
<p>In this article, we’ll use the same data set suggested in the <a class="reference external" href="https://www.kaggle.com/code/rohanrao/tutorial-on-reading-large-datasets">Kaggle Tutorial on Large Datasets</a>, the <a class="reference external" href="https://www.kaggle.com/c/riiid-test-answer-prediction">Riiid Answer Prediction Dataset</a>. This is a data set of student test scores over time, which aimed to show how students would perform in the future given their past learning history. More to the point for our purposes, the training dataset (in training.csv) weighs in at some 5.4 Gb, so it’s large enough that loading it is a challenge.</p>
</section>
<section id="setting-up-our-environment">
<h2>Setting Up Our Environment<a class="headerlink" href="#setting-up-our-environment" title="Link to this heading"></a></h2>
<p>To create our environment, we installed a clean Python 3.11 release using conda, then set up a virtual environment using Pip. We did not use Conda to install the packages because some of them had dependency conflicts, so we opted for the (more permissive) pip tool to install everything successfully.</p>
<p>We used the following commands to accomplish this. You can easily skip the first two lines if you don’t have Conda installed.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>python3.11<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.11
conda<span class="w"> </span>activate<span class="w"> </span>python3.11
python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>.venv
<span class="nb">source</span><span class="w"> </span>.venv/bin/activate
pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
pip<span class="w"> </span>install<span class="w"> </span>jupyterlab<span class="w"> </span>ipython<span class="w"> </span>pandas<span class="w"> </span>dask<span class="w"> </span>polars<span class="w"> </span>fastparquet
</pre></div>
</div>
<p>We timed some initial tests using timeit programmatically, as described in How to Profile Python Code. Still, since timeit can be a bit unwieldy for running several tests, we improved upon some code we found that did a reasonable job of setting up a timer in a context manager, so we could easily test a block of code. Here is that code in timer.py</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="k">class</span> <span class="nc">Timer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Allows setting up a timer as a context manager, for example:</span>
<span class="sd">       with Timer(&quot;My process&quot;):</span>
<span class="sd">           # Code you want to time here</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tstart</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">traceback</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[</span><span class="si">%s</span><span class="s1">]&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,)</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tstart</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Elapsed time: </span><span class="si">{</span><span class="n">elapsed</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We first wanted to determine our baseline performance for loading the CSV in Pandas as we usually would.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read from CSV</span>
<span class="kn">from</span> <span class="nn">timer</span> <span class="kn">import</span> <span class="n">Timer</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Pandas plain read_csv&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/train.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output (typical):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>Pandas<span class="w"> </span>plain<span class="w"> </span>read_csv<span class="o">]</span>
Elapsted<span class="w"> </span>time:<span class="w"> </span><span class="m">35</span>.65<span class="w"> </span>seconds
</pre></div>
</div>
<p>Before dealing with other file types or non-Pandas libraries, let’s try the “minimally invasive” approach of making the data types explicit. Pandas tend to load everything as a float64, but we can be more precise about things. Looking at the data using <code class="docutils literal notranslate"><span class="pre">df.head()</span></code>, we can set up the following dictionary of column names to data types for the data that’s displayed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">dtypes</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">&#39;row_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
 <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
 <span class="s1">&#39;user_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
 <span class="s1">&#39;content_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
 <span class="s1">&#39;content_type_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
<span class="s1">&#39;task_container_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
<span class="s1">&#39;user_answer&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
<span class="s1">&#39;answered_correctly&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
<span class="s1">&#39;prior_question_elapsed_time&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> 
<span class="s1">&#39;prior_question_had_explanation&#39;</span><span class="p">:</span> <span class="nb">object</span>
<span class="p">}</span>
</pre></div>
</div>
<p>With this in place, let’s see if we did any good.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read from CSV with types specified</span>
<span class="kn">from</span> <span class="nn">timer</span> <span class="kn">import</span> <span class="n">Timer</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Pandas read_csv with types&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/train.csv&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>Pandas<span class="w"> </span>read_csv<span class="w"> </span>with<span class="w"> </span>types<span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">31</span>.82<span class="w"> </span>seconds
</pre></div>
</div>
<p>OK, we’ve shaved off a little less than three seconds, so it’s something, but it’s still not great.</p>
<p>Let’s see if we can do any better with a different library.</p>
</section>
<section id="polars-a-fast-dataframe-implementation-with-a-slick-api">
<h2>Polars: A Fast DataFrame implementation with a Slick API<a class="headerlink" href="#polars-a-fast-dataframe-implementation-with-a-slick-api" title="Link to this heading"></a></h2>
<p>Polars is billed as a “Lightning-fast DataFrame library for Rust and Python.” It features faster read performance (which we’ll show in a minute) and a lazy mode where expressions (such as grouping, selecting rows, etc.) are optimized and run in parallel.</p>
<p>As a bonus, I also believe that the expression syntax is often far more intuitive in Polars than indexing methods in Pandas, such as <code class="docutils literal notranslate"><span class="pre">loc</span></code> and <code class="docutils literal notranslate"><span class="pre">iloc</span></code>.</p>
<p>Before getting into some of these advanced features, let’s do a non-lazy read of the whole DataFrame in Polars to see how it compares to read_csv in Pandas. For this operation, the function name we want is the same.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">polars</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">timer</span> <span class="kn">import</span> <span class="n">Timer</span>

<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Read csv using polars&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/train.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>Read<span class="w"> </span>csv<span class="w"> </span>using<span class="w"> </span>polars<span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">9</span>.98<span class="w"> </span>seconds
</pre></div>
</div>
<p>Well, that’s much better – now we’re loading the file in about 1/3 the time it took to load using Pandas. In fairness, I should point out that the 9.98 seconds is on the low end of the Polars results, using a brand new kernel. When running interactively in Jupyter Notebook, times of 12-14 seconds are more typical, but that’s still a big improvement on the load times for Pandas.</p>
</section>
<section id="large-data-sets-with-alternate-file-types">
<h2>Large Data Sets With Alternate File Types<a class="headerlink" href="#large-data-sets-with-alternate-file-types" title="Link to this heading"></a></h2>
<p>In addition to selecting a different library, another approach to improving file load performance is to use an alternate file type. Data files are often available in CSV format. Still, CSV’s popularity comes from being human-readable and widely supported, not because it can be loaded quickly for large files.</p>
<p>One issue with this approach is that the libraries that support other file types don’t always work in all environments. Especially on my M1 (Apple Silicon) Mac, building these libraries have been problematic. For example, the Pandas “feather” format relies on PyArrow, which is not readily installable (though there may be <a class="reference external" href="https://github.com/python-poetry/poetry/issues/3627">workarounds</a> if you need to install it).</p>
<p>I’ve had better luck with reading and writing parquet files using fastparquet. Still, even with this, the to_parquet method of the Pandas DataFrame threw a data type conversion error after several seconds.</p>
<p>I was able to both write the file and read it back successfully using Polars, and once this was done, it also became readable using Pandas. The downside is that loading the code in Polars from CSV and writing it back to parquet format took about 30 seconds. Once this is done, however, reading the same data set in parquet format sped things up considerably compared to CSV, both for Pandas and Polars. Here are the code and the results:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">polars</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">timer</span> <span class="kn">import</span> <span class="n">Timer</span>

<span class="c1"># Be patient, this will take several seconds</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/train.csv&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">write_parquet</span><span class="p">(</span><span class="s2">&quot;data/train.parquet&quot;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Time to read from parquet in Pandas&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s2">&quot;data/train.parquet&quot;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Time to read from parquet in Polars&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s2">&quot;data/train.parquet&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>Time<span class="w"> </span>to<span class="w"> </span><span class="nb">read</span><span class="w"> </span>from<span class="w"> </span>parquet<span class="w"> </span><span class="k">in</span><span class="w"> </span>Pandas<span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">7</span>.07<span class="w"> </span>seconds
<span class="o">[</span>Time<span class="w"> </span>to<span class="w"> </span><span class="nb">read</span><span class="w"> </span>from<span class="w"> </span>parquet<span class="w"> </span><span class="k">in</span><span class="w"> </span>Polars<span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">4</span>.51<span class="w"> </span>seconds
</pre></div>
</div>
</section>
<section id="speeding-things-up-with-lazy-mode">
<h2>Speeding Things Up With Lazy Mode<a class="headerlink" href="#speeding-things-up-with-lazy-mode" title="Link to this heading"></a></h2>
<p>So far, our discussion of load times has been mainly concerned with a single question: How can we move 5.4 gigabytes (or some similar, large amount) of data as efficiently as possible from disk storage into an in-memory DataFrame so we can further manipulate it?</p>
<p>In this section, we want to take a step back and ask: Is moving 5.4 gigabytes from disk storage to memory the right approach? Reading data and moving it around takes time. (That’s always true even for small data sets like the 150 rows and five columns of iris.csv, but for such tiny data sets we don’t notice the problem).</p>
<p>Instead of reading it all in data and manipulating it, what if we could plan our query in advance to only load the rows and columns we need for our analysis?</p>
<p>This question brings us to the heart of what Polars calls “lazy mode,” but the solution is not unique to Polars. In Spark, both Spark SQL and Spark DataFrames work using a common Catalyst optimizer, a query optimizer that finds an efficient way to fetch data satisfying a group of Spark expressions. Similarly, Dask DataFrames has an API that is similar to Pandas on the face of it, except that data is lazily loaded from a file when compute is called on a query.</p>
</section>
<section id="dask-vs-polars-lazy-mode-showdown">
<h2>Dask vs. Polars: Lazy Mode Showdown<a class="headerlink" href="#dask-vs-polars-lazy-mode-showdown" title="Link to this heading"></a></h2>
<p>This section contains some background, a confession, and a spoiler alert.</p>
<p>Let’s do it in just that order.</p>
<ul class="simple">
<li><p><strong>The background:</strong> For this article, it was somewhat impractical to review every solution and library we tried to show how lazy loading might work. Developing a large test suite to exercise different queries was also not something we had time to engineer for this article, so we had to make some choices. Specifically, we decided to focus on a simple test case, fetching rows for a given user.</p></li>
<li><p><strong>The confession:</strong> After I’d run my tests in Dask, I saw this caveat on their <a class="reference external" href="https://docs.dask.org/en/stable/dataframe-best-practices.html">Dask best practices</a> page. “<em>For data that fits into RAM, pandas can often be faster and easier to use than Dask DataFrame. While “Big Data” tools can be exciting, they are almost always worse than normal data tools while those remain appropriate.”</em> This is again proof of the age-old axiom that if you want to hide something from a developer, put it in the manual. So it may be that a really fair test between Dask would be at a larger scale. However, <a class="reference external" href="https://h2oai.github.io/db-benchmark/" title="this benchmark">this benchmark</a> suggests that even at that scale, Polars will do better.</p></li>
<li><p><strong>The spoiler alert:</strong> OK, I spilled the beans in the last bullet point, but here if you missed it is the spoiler alert. Polars worked better than Dask. A lot better.</p></li>
</ul>
<p>I wanted to give you the background and the confession first because I know a lot of time and effort went into Dask, so I don’t want any Dask developers or fans to think I walked into this comparison wanting to make it look bad.</p>
<p>Now that we know the result we arrived at, let’s share the details of how we got there.</p>
<section id="lazy-loading-of-rows-in-dask">
<h3>Lazy Loading of Rows in Dask<a class="headerlink" href="#lazy-loading-of-rows-in-dask" title="Link to this heading"></a></h3>
<p>Unlike Polars, but like Pandas, many operations for selecting rows depend on what index is set. The Dask documentation advises us to set the index once since it’s expensive and to cache it back to the dataframe object.</p>
<p>Let’s take a look at the cost of this and the results for retrieving a set of rows from fairly early in the file. (We use both the “dtype” setting and the low_memory setting on read_csv to avoid a warning in Dask).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dask</span> <span class="kn">import</span> <span class="n">dataframe</span>
<span class="kn">from</span> <span class="nn">timer</span> <span class="kn">import</span> <span class="n">Timer</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">dtypes</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">&#39;row_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
 <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
 <span class="s1">&#39;user_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
 <span class="s1">&#39;content_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
 <span class="s1">&#39;content_type_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
<span class="s1">&#39;task_container_id&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
<span class="s1">&#39;user_answer&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> 
<span class="s1">&#39;answered_correctly&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
<span class="s1">&#39;prior_question_elapsed_time&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> 
<span class="s1">&#39;prior_question_had_explanation&#39;</span><span class="p">:</span> <span class="nb">object</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;dask read_csv&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/train.csv&quot;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;set_index.csv&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;user_id&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>dask<span class="w"> </span>read_csv<span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">0</span>.03<span class="w"> </span>seconds
<span class="o">[</span>set_index.csv<span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">33</span>.62<span class="w"> </span>seconds
</pre></div>
</div>
<p>Note that the read_csv operation only took about 30 milliseconds. No data is really fetched in Dask until you do a “compute”. The next line, setting the index, took about as long as reading the whole file in memory took using Pandas. Let’s see if it was worth it as we retrieve the rows for the user with ID 40828; we’ll save them as we would to display them or operate on them further</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Get rows for user_id 40828&quot;</span><span class="p">):</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">40828</span><span class="p">]</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>Get<span class="w"> </span>rows<span class="w"> </span><span class="k">for</span><span class="w"> </span>user_id<span class="w"> </span><span class="m">40828</span><span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">32</span>.70<span class="w"> </span>seconds
</pre></div>
</div>
<p>Once again, even with the index set, it still took over half a minute to read the rows! Pandas could surely do better than this in memory. In fact, let’s find out. This is with the data reloaded using read_csv in Pandas:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Pandas set_index_and_fetch&quot;</span><span class="p">):</span>
    <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;user_id&quot;</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">40828</span><span class="p">]</span>

<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Fetch portion only&quot;</span><span class="p">):</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">40828</span><span class="p">]</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>Pandas<span class="w"> </span>set_index_and_fetch<span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">4</span>.29<span class="w"> </span>seconds
<span class="o">[</span>Fetch<span class="w"> </span>portion<span class="w"> </span>only<span class="o">]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">0</span>.00<span class="w"> </span>seconds
</pre></div>
</div>
</section>
<section id="lazy-mode-in-polars">
<h3>Lazy Mode in Polars<a class="headerlink" href="#lazy-mode-in-polars" title="Link to this heading"></a></h3>
<p>Now let’s see if we can use lazy mode in Polars to just retrieve a few rows. To do this, we’ll use the <code class="docutils literal notranslate"><span class="pre">scan_csv</span></code> method, which does not read the whole file in memory as <code class="docutils literal notranslate"><span class="pre">read_csv</span></code> does, instead, it will only retrieve the rows that match the filter expression. We won’t have to set an index as we would in Dask or Pandas.</p>
<p>We’ll try to select the same user from early in the file as we did with Dask and Pandas, then we’ll do the same thing for a user later in the file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">polars</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">timer</span> <span class="kn">import</span> <span class="n">Timer</span> 

<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Scan CSV for early user (Polars)&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">scan_csv</span><span class="p">(</span><span class="s2">&quot;data/train.csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s1">&#39;user_id&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="mi">40828</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="s2">&quot;Read CSV for later user (Polars)&quot;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">scan_csv</span><span class="p">(</span><span class="s2">&quot;data/train.csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s1">&#39;user_id&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2147470777</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Scan<span class="w"> </span>CSV<span class="w"> </span><span class="k">for</span><span class="w"> </span>early<span class="w"> </span>user<span class="w"> </span><span class="o">(</span>Polars<span class="o">)]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">3</span>.53<span class="w"> </span>seconds
<span class="o">[</span>Read<span class="w"> </span>CSV<span class="w"> </span><span class="k">for</span><span class="w"> </span>later<span class="w"> </span>user<span class="w"> </span><span class="o">(</span>Polars<span class="o">)]</span>
Elapsed<span class="w"> </span>time:<span class="w"> </span><span class="m">3</span>.10<span class="w"> </span>seconds
</pre></div>
</div>
</section>
</section>
<section id="closing-thoughts">
<h2>Closing Thoughts<a class="headerlink" href="#closing-thoughts" title="Link to this heading"></a></h2>
<p>I have been looking for an opportunity to evaluate Dask. I’m open to the possibility that it might be worthwhile for other use cases, but it didn’t work well for the things I tried. I would be inclined to look at PySpark next rather than spend more time on it.</p>
<p>On the other hand, Polars has turned in some extremely impressive results here.</p>
<p>We began our discussion loading a 5.4 Gb CSV file into Pandas in about 35 seconds, and we’re now able to locate and extract rows for a given user in about 1/10th of that time using Polars. Along the way, we were also able to show that Polars loaded large CSV files into memory about three times faster than Pandas.</p>
<p>Pandas still maintains an edge for selecting rows once an index is set (which itself takes about 4 seconds). However, for the “everything in memory case”, Polars can still retrieve the same set of rows fairly quickly too (about 90 milliseconds or so).</p>
<p>Given that interactive data analysis involves a lot of ad-hoc queries where you may be doing filtering on different columns, I see this as a win. In Polars, if you want to filter on a different column or set of columns, you don’t need to switch indexes to do it.</p>
<p>Another interesting feature of Polars is that it’s written in Rust and has a Rust API, which in principle allows the optimization of key operations. I haven’t yet been able to demonstrate a significant improvement on file read, so it does appear that most of the time spent here is on simple IO rather than at the Rust/Python boundary. However, but it may be that for other operations there are savings to be had.</p>
</section>
<section id="you-may-also-like">
<h2>You May Also Like<a class="headerlink" href="#you-may-also-like" title="Link to this heading"></a></h2>
<p><a class="reference external" href="https://codesolid.com/pandas-groupby/">How to Use the Pandas GroupBy Method</a></p>
<p><a class="reference external" href="https://codesolid.com/python-format-strings/">Pandas Practice Questions</a></p>
<p><a class="reference external" href="https://codesolid.com/python-operators/">Python Operators: The Building Blocks of Successful Code</a></p>
<p><a class="reference external" href="https://codesolid.com/python-function-arguments-and-parameters-examples/">Python Function Arguments: The Complete Guide</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../data-cleaning-in-pandas/" class="btn btn-neutral float-left" title="Data cleaning in Pandas" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../pandas-groupby/" class="btn btn-neutral float-right" title="How to Use the Pandas Groupby Method?" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, John Lockwood.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-QX7KGT4YPE"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-QX7KGT4YPE', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>